{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "145e9ed2-4441-4da6-ac94-44c3b75eebd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "from langchain import LLMChain\n",
    "from langchain.chat_models import AzureChatOpenAI\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.chains import ConversationChain\n",
    "from langchain.prompts import ChatPromptTemplate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44096e4b-d090-4629-be03-e0e697e1692e",
   "metadata": {},
   "source": [
    "Why Langchain Prompts over f-string:\n",
    "- Prompts could be very long and detailed\n",
    "- Reuse prompt when you can!\n",
    "- Langchain also provide prompts for common operations\n",
    "- Output Parsing:\n",
    "- Thought / Action / Observation\n",
    "\n",
    "Why Memory:\n",
    "- LLMs are stateless\n",
    "    - Each transaction is independant\n",
    "- Chatbots appears to have memory by providing the full conversation as context\n",
    "- Types:\n",
    "    - ConversationBufferMemory\n",
    "    - ConversationBufferWindowMemory\n",
    "    - ConversationTokenBufferMemory\n",
    "    - ConversationSummaryMemory\n",
    "    - Vector data memory\n",
    "    - Entity memories\n",
    "    \n",
    "Chains:\n",
    "- "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9bc9c2b7-fb3e-4e3a-b3b6-14cb5fbe8fd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../configs/config.json', 'r') as f:\n",
    "    config = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "254a9735-813c-487e-9c18-1b7343b079dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['OPENAI_API_TYPE']=config['OPENAI_API_TYPE']\n",
    "os.environ['OPENAI_API_VERSION']=config['OPENAI_API_VERSION']\n",
    "os.environ['OPENAI_API_BASE']=config['OPENAI_API_BASE']\n",
    "os.environ['OPENAI_API_KEY']=config['OPENAI_API_KEY']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9389f303-cd30-4f87-8778-e4d0d5d350c4",
   "metadata": {},
   "source": [
    "## Chatbot using Langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "add4e0c5-00ae-41fa-b1d0-6cd60a9e471b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the LLM model\n",
    "llm = AzureChatOpenAI(deployment_name=config['OPENAI_MODEL_NAME'], \n",
    "                       model_name=\"gpt-35-turbo\", \n",
    "                       temperature=0.0)\n",
    "\n",
    "memory = ConversationBufferMemory()\n",
    "conversation = ConversationChain(\n",
    "                        llm=llm, \n",
    "                        memory=memory,\n",
    "                        verbose=False\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8bd0c5ea-f644-4694-a53f-cf34d7718559",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Hello Amit, it's nice to meet you. My name is AI. How can I assist you today?\""
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input=\"Hi, my name is Amit\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2775dd82-a2da-47d8-bf39-99e828fb15db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The answer to 1+1 is 2.'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input=\"What is 1+1?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9a6c6855-3af0-4721-a35c-77db227df8aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Your name is Amit, as you mentioned earlier.'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input=\"What is my name?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "81a0ca88-efe2-4336-8b62-83eddb5a21a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Human: Hi, my name is Amit\n",
      "AI: Hello Amit, it's nice to meet you. My name is AI. How can I assist you today?\n",
      "Human: What is 1+1?\n",
      "AI: The answer to 1+1 is 2.\n",
      "Human: What is my name?\n",
      "AI: Your name is Amit, as you mentioned earlier.\n"
     ]
    }
   ],
   "source": [
    "print(memory.buffer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a441adbe-239d-432d-9f4f-dde1047fcf12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': \"Human: Hi, my name is Amit\\nAI: Hello Amit, it's nice to meet you. My name is AI. How can I assist you today?\\nHuman: What is 1+1?\\nAI: The answer to 1+1 is 2.\\nHuman: What is my name?\\nAI: Your name is Amit, as you mentioned earlier.\"}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9bef452b-2480-45a5-82fb-dd6e608a52f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "memory = ConversationBufferMemory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c651c031-513f-459f-bfbb-f49149fcae19",
   "metadata": {},
   "outputs": [],
   "source": [
    "memory.save_context({\"input\": \"Hi\"}, \n",
    "                    {\"output\": \"What's up\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d306c5b9-001f-4546-802d-68aad6620de1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Human: Hi\n",
      "AI: What's up\n"
     ]
    }
   ],
   "source": [
    "print(memory.buffer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "03aa68f0-0415-4e6c-894b-c204ac47ed0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': \"Human: Hi\\nAI: What's up\"}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a3ec9e8f-9107-4eea-9522-a4eec6d615a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "memory.save_context({\"input\": \"Not much, just hanging\"}, \n",
    "                    {\"output\": \"Cool\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "73fc9d08-937b-4002-a3fd-80326ac7e676",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': \"Human: Hi\\nAI: What's up\\nHuman: Not much, just hanging\\nAI: Cool\"}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d501206a-2d57-45e2-aef5-fe9e9a21a438",
   "metadata": {},
   "source": [
    "## ConversationBufferWindowMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f9cef86e-1955-466c-8bd8-c98a69fe3727",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationBufferWindowMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "3352b29a-2b7a-484c-988b-21a5ebf91e55",
   "metadata": {},
   "outputs": [],
   "source": [
    "memory = ConversationBufferWindowMemory(k=1)               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "135ea5c8-35d1-47a7-bb3e-c751f9f3ca0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "memory.save_context({\"input\": \"Hi\"},\n",
    "                    {\"output\": \"What's up\"})\n",
    "memory.save_context({\"input\": \"Not much, just hanging\"},\n",
    "                    {\"output\": \"Cool\"})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "476175d2-f558-4265-b728-362403ddeeb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': 'Human: Not much, just hanging\\nAI: Cool'}"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "031db1a7-42a3-44a3-9ee0-3ceb933e2535",
   "metadata": {},
   "outputs": [],
   "source": [
    "memory = ConversationBufferWindowMemory(k=1)\n",
    "conversation = ConversationChain(\n",
    "    llm=llm, \n",
    "    memory = memory,\n",
    "    verbose=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "03c1e8be-34bc-470c-b462-6b9d0332e8c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Hello Amit, it's nice to meet you. My name is AI. How can I assist you today?\""
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input=\"Hi, my name is Amit\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "976b323a-e7f1-4bf2-91e9-36a6b5eaa8a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The answer to 1+1 is 2.'"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input=\"What is 1+1?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "ceda9d2f-3e92-4499-bfe1-773bca0541c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I'm sorry, I don't have access to that information. Could you please tell me your name?\""
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input=\"What is my name?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1361a8f6-3982-46b4-863c-54b29e48a991",
   "metadata": {},
   "source": [
    "## ConversationTokenBufferMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "2400eabe-7ad7-4aba-8191-34b14b789fb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationTokenBufferMemory\n",
    "\n",
    "#memory = ConversationTokenBufferMemory(llm=llm, max_token_limit=30)\n",
    "\n",
    "#memory.save_context({\"input\": \"AI is what?!\"},\n",
    "#                    {\"output\": \"Amazing!\"})\n",
    "#memory.save_context({\"input\": \"Backpropagation is what?\"},\n",
    "#                    {\"output\": \"Beautiful!\"})\n",
    "#memory.save_context({\"input\": \"Chatbots are what?\"}, \n",
    "#                    {\"output\": \"Charming!\"})\n",
    "#memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f93cc3d8-057a-4aab-962e-787d06385d0d",
   "metadata": {},
   "source": [
    "## ConversationSummaryMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "2d41d114-8e87-4e34-8235-0dea9660ed8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationSummaryBufferMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "311d34cc-8a22-4006-8b98-ced7837221f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a long string\n",
    "#schedule = \"There is a meeting at 8am with your product team. \\\n",
    "#You will need your powerpoint presentation prepared. \\\n",
    "#9am-12pm have time to work on your LangChain \\\n",
    "#project which will go quickly because Langchain is such a powerful tool. \\\n",
    "#At Noon, lunch at the italian resturant with a customer who is driving \\\n",
    "#from over an hour away to meet you to understand the latest in AI. \\\n",
    "#Be sure to bring your laptop to show the latest LLM demo.\"\n",
    "\n",
    "#memory = ConversationSummaryBufferMemory(llm=llm, max_token_limit=100)\n",
    "#memory.save_context({\"input\": \"Hello\"}, {\"output\": \"What's up\"})\n",
    "#memory.save_context({\"input\": \"Not much, just hanging\"},\n",
    "#                    {\"output\": \"Cool\"})\n",
    "#memory.save_context({\"input\": \"What is on the schedule today?\"}, \n",
    "#                    {\"output\": f\"{schedule}\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "f546e37a-5e69-4efe-bb3d-2f423d421a0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#memory.load_memory_variables({})\n",
    "#conversation = ConversationChain(\n",
    "#    llm=llm, \n",
    "#    memory = memory,\n",
    "#    verbose=True\n",
    "#)\n",
    "\n",
    "#conversation.predict(input=\"What would be a good demo to show?\")\n",
    "#memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65a5ec40-9928-4738-9f61-3f5e63b8be97",
   "metadata": {},
   "source": [
    "## Chains"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2742a3b1-4755-4837-b5c6-b5f8548e9b87",
   "metadata": {},
   "source": [
    "![Simple Seuqntial Chain](../images/sequential_chains.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "f43d10c4-6063-4cbb-a864-06bb772db1b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = '../data/Data.csv'\n",
    "df = pd.read_csv(file, sep=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "105b1f6f-6780-4647-b4e9-edca3f743709",
   "metadata": {},
   "source": [
    "### LLMChain\n",
    "Basic chain which combines a model and a prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "a23ac8e3-984d-4658-80e1-94f7f54cf7ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.chains import LLMChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "9d762722-862d-46db-aba7-477de5cce8d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = AzureChatOpenAI(deployment_name=config['OPENAI_MODEL_NAME'], \n",
    "                       model_name=\"gpt-35-turbo\", \n",
    "                       temperature=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "28205908-ec34-4de3-ab0d-0b4fdb7eee63",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = ChatPromptTemplate.from_template(\n",
    "    \"What is the best name to describe \\\n",
    "    a company that makes {product}?\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "2141d327-cc5c-4726-8601-a77ca6665fa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = LLMChain(llm=llm, prompt=prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "c82c84a4-cac4-4e06-9458-197d98a54d3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Royal Bedding Company'"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "product = \"Queen Size Sheet Set\"\n",
    "chain.run(product)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d75ff9d0-1bef-432e-9ee5-ca22c370e1f1",
   "metadata": {},
   "source": [
    "## SimpleSequentialChain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97808193-7a8b-464e-bc23-29f572a303b1",
   "metadata": {},
   "source": [
    "![Simple Seuqntial Chain](../images/simple_sequential_chain.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "91f187e8-4484-46c4-9266-aac03e3a8e73",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import SimpleSequentialChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "243f5a59-4d0c-4d3d-9e53-955ffbb2874a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt template 1\n",
    "first_prompt = ChatPromptTemplate.from_template(\n",
    "    \"What is the best name to describe \\\n",
    "    a company that makes {product}?\"\n",
    ")\n",
    "\n",
    "# Chain 1\n",
    "chain_one = LLMChain(llm=llm, prompt=first_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "cfb65528-3a2e-4520-b5af-9707c773f9f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt template 2\n",
    "second_prompt = ChatPromptTemplate.from_template(\n",
    "    \"Write a 20 words description for the following \\\n",
    "    company:{company_name}\"\n",
    ")\n",
    "# chain 2\n",
    "chain_two = LLMChain(llm=llm, prompt=second_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "e86a6eac-cd8f-4a22-ad3f-7663d9a7c677",
   "metadata": {},
   "outputs": [],
   "source": [
    "overall_simple_chain = SimpleSequentialChain(chains=[chain_one, chain_two],\n",
    "                                             verbose=True\n",
    "                                            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "f0a969fb-2965-4e49-922d-d2e997d0c1af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new SimpleSequentialChain chain...\u001b[0m\n",
      "\u001b[36;1m\u001b[1;3mRegal Linens.\u001b[0m\n",
      "\u001b[33;1m\u001b[1;3mRegal Linens offers a wide selection of luxury bed linens, bath towels, and other home essentials for a comfortable and stylish living.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Regal Linens offers a wide selection of luxury bed linens, bath towels, and other home essentials for a comfortable and stylish living.'"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "overall_simple_chain.run(product)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "261b46a1-cf29-495f-9126-0ebe48bbfad6",
   "metadata": {},
   "source": [
    "## SequentialChain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62558fd8-bf08-4507-9119-5c14788d00c0",
   "metadata": {},
   "source": [
    "![Simple Seuqntial Chain](../images/sequential_chain.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "8b5a73b8-2e23-4714-831d-827b5b469295",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import SequentialChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "44566191-24f2-41bf-b471-25d415e546dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt template 1: translate to english\n",
    "first_prompt = ChatPromptTemplate.from_template(\n",
    "    \"Translate the following review to english:\"\n",
    "    \"\\n\\n{Review}\"\n",
    ")\n",
    "# chain 1: input= Review and output= English_Review\n",
    "chain_one = LLMChain(llm=llm, prompt=first_prompt, \n",
    "                     output_key=\"English_Review\"\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "8351cc40-298e-43c9-945a-4c932503efe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "second_prompt = ChatPromptTemplate.from_template(\n",
    "    \"Can you summarize the following review in 1 sentence:\"\n",
    "    \"\\n\\n{English_Review}\"\n",
    ")\n",
    "# chain 2: input= English_Review and output= summary\n",
    "chain_two = LLMChain(llm=llm, prompt=second_prompt, \n",
    "                     output_key=\"summary\"\n",
    "                    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "5a41480e-da43-4beb-b1d1-81c3ec2e9e7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt template 3: translate to english\n",
    "third_prompt = ChatPromptTemplate.from_template(\n",
    "    \"What language is the following review:\\n\\n{Review}\"\n",
    ")\n",
    "# chain 3: input= Review and output= language\n",
    "chain_three = LLMChain(llm=llm, prompt=third_prompt,\n",
    "                       output_key=\"language\"\n",
    "                      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "01bcad92-a143-4c26-a8d5-ab26885ec73e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt template 4: follow up message\n",
    "fourth_prompt = ChatPromptTemplate.from_template(\n",
    "    \"Write a follow up response to the following \"\n",
    "    \"summary in the specified language:\"\n",
    "    \"\\n\\nSummary: {summary}\\n\\nLanguage: {language}\"\n",
    ")\n",
    "# chain 4: input= summary, language and output= followup_message\n",
    "chain_four = LLMChain(llm=llm, prompt=fourth_prompt,\n",
    "                      output_key=\"followup_message\"\n",
    "                     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "e108cd00-a601-4e0e-895a-086e820a31b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# overall_chain: input= Review \n",
    "# and output= English_Review,summary, followup_message\n",
    "overall_chain = SequentialChain(\n",
    "    chains=[chain_one, chain_two, chain_three, chain_four],\n",
    "    input_variables=[\"Review\"],\n",
    "    output_variables=[\"English_Review\", \"summary\",\"followup_message\"],\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "8ecffabe-94aa-43f0-8632-058e963dd803",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Review': \"Je trouve le goût médiocre. La mousse ne tient pas, c'est bizarre. J'achète les mêmes dans le commerce et le goût est bien meilleur...\\nVieux lot ou contrefaçon !?\",\n",
       " 'English_Review': '\"I find the taste mediocre. The foam does not hold up, which is strange. I buy the same thing from the store and the taste is much better... Old batch or counterfeit!?\"',\n",
       " 'summary': \"The reviewer thinks the taste of the product they received is mediocre and suspects it may be an old batch or counterfeit because the foam doesn't hold up as well as the store-bought version.\",\n",
       " 'followup_message': \"Réponse de suivi:\\n\\nNous sommes désolés d'apprendre que le produit que vous avez reçu n'a pas répondu à vos attentes en termes de goût et de qualité. Nous prenons très au sérieux les préoccupations de nos clients en matière d'authenticité et nous travaillons dur pour nous assurer que tous nos produits sont frais et de la plus haute qualité. Nous aimerions en savoir plus sur votre expérience afin de pouvoir enquêter sur cette question. Si vous pouviez nous contacter directement avec plus de détails sur votre achat, nous serions heureux de vous aider à résoudre ce problème. Merci de votre compréhension.\"}"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review = df.Review[5]\n",
    "overall_chain(review)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14fd5b14-8443-42eb-80f6-f3cf8d781b30",
   "metadata": {},
   "source": [
    "## Router Chain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0119201c-3ad4-4895-9141-0fe4ded5272e",
   "metadata": {},
   "source": [
    "![Simple Seuqntial Chain](../images/router_chain.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "f4da13db-d802-4ee7-9263-2c67a8e2e5d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains.router import MultiPromptChain\n",
    "from langchain.chains.router.llm_router import LLMRouterChain,RouterOutputParser\n",
    "from langchain.prompts import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "7066f7a5-1474-4fd7-9f0c-25017c558907",
   "metadata": {},
   "outputs": [],
   "source": [
    "physics_template = \"\"\"You are a very smart physics professor. \\\n",
    "You are great at answering questions about physics in a concise\\\n",
    "and easy to understand manner. \\\n",
    "When you don't know the answer to a question you admit\\\n",
    "that you don't know.\n",
    "\n",
    "Here is a question:\n",
    "{input}\"\"\"\n",
    "\n",
    "\n",
    "math_template = \"\"\"You are a very good mathematician. \\\n",
    "You are great at answering math questions. \\\n",
    "You are so good because you are able to break down \\\n",
    "hard problems into their component parts, \n",
    "answer the component parts, and then put them together\\\n",
    "to answer the broader question.\n",
    "\n",
    "Here is a question:\n",
    "{input}\"\"\"\n",
    "\n",
    "history_template = \"\"\"You are a very good historian. \\\n",
    "You have an excellent knowledge of and understanding of people,\\\n",
    "events and contexts from a range of historical periods. \\\n",
    "You have the ability to think, reflect, debate, discuss and \\\n",
    "evaluate the past. You have a respect for historical evidence\\\n",
    "and the ability to make use of it to support your explanations \\\n",
    "and judgements.\n",
    "\n",
    "Here is a question:\n",
    "{input}\"\"\"\n",
    "\n",
    "\n",
    "computerscience_template = \"\"\" You are a successful computer scientist.\\\n",
    "You have a passion for creativity, collaboration,\\\n",
    "forward-thinking, confidence, strong problem-solving capabilities,\\\n",
    "understanding of theories and algorithms, and excellent communication \\\n",
    "skills. You are great at answering coding questions. \\\n",
    "You are so good because you know how to solve a problem by \\\n",
    "describing the solution in imperative steps \\\n",
    "that a machine can easily interpret and you know how to \\\n",
    "choose a solution that has a good balance between \\\n",
    "time complexity and space complexity. \n",
    "\n",
    "Here is a question:\n",
    "{input}\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "07178c91-9bbd-44bf-9a08-7ffddf8317b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_infos = [\n",
    "    {\n",
    "        \"name\": \"physics\", \n",
    "        \"description\": \"Good for answering questions about physics\", \n",
    "        \"prompt_template\": physics_template\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"math\", \n",
    "        \"description\": \"Good for answering math questions\", \n",
    "        \"prompt_template\": math_template\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"History\", \n",
    "        \"description\": \"Good for answering history questions\", \n",
    "        \"prompt_template\": history_template\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"computer science\", \n",
    "        \"description\": \"Good for answering computer science questions\", \n",
    "        \"prompt_template\": computerscience_template\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "5edc63c1-6346-4caf-814a-30496adb6af3",
   "metadata": {},
   "outputs": [],
   "source": [
    "destination_chains = {}\n",
    "for p_info in prompt_infos:\n",
    "    name = p_info[\"name\"]\n",
    "    prompt_template = p_info[\"prompt_template\"]\n",
    "    prompt = ChatPromptTemplate.from_template(template=prompt_template)\n",
    "    chain = LLMChain(llm=llm, prompt=prompt)\n",
    "    destination_chains[name] = chain  \n",
    "    \n",
    "destinations = [f\"{p['name']}: {p['description']}\" for p in prompt_infos]\n",
    "destinations_str = \"\\n\".join(destinations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "ed25c1be-f005-4d5a-b82b-80a7784af575",
   "metadata": {},
   "outputs": [],
   "source": [
    "default_prompt = ChatPromptTemplate.from_template(\"{input}\")\n",
    "default_chain = LLMChain(llm=llm, prompt=default_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "ebd9d25d-05da-4bb6-b8d7-4b73675ca5b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "MULTI_PROMPT_ROUTER_TEMPLATE = \"\"\"Given a raw text input to a \\\n",
    "language model select the model prompt best suited for the input. \\\n",
    "You will be given the names of the available prompts and a \\\n",
    "description of what the prompt is best suited for. \\\n",
    "You may also revise the original input if you think that revising\\\n",
    "it will ultimately lead to a better response from the language model.\n",
    "\n",
    "<< FORMATTING >>\n",
    "Return a markdown code snippet with a JSON object formatted to look like:\n",
    "```json\n",
    "{{{{\n",
    "    \"destination\": string \\ name of the prompt to use or \"DEFAULT\"\n",
    "    \"next_inputs\": string \\ a potentially modified version of the original input\n",
    "}}}}\n",
    "```\n",
    "\n",
    "REMEMBER: \"destination\" MUST be one of the candidate prompt \\\n",
    "names specified below OR it can be \"DEFAULT\" if the input is not\\\n",
    "well suited for any of the candidate prompts.\n",
    "REMEMBER: \"next_inputs\" can just be the original input \\\n",
    "if you don't think any modifications are needed.\n",
    "\n",
    "<< CANDIDATE PROMPTS >>\n",
    "{destinations}\n",
    "\n",
    "<< INPUT >>\n",
    "{{input}}\n",
    "\n",
    "<< OUTPUT (remember to include the ```json)>>\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "8e1dfe4f-872d-493b-b5a9-0353025a3f8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "router_template = MULTI_PROMPT_ROUTER_TEMPLATE.format(\n",
    "    destinations=destinations_str\n",
    ")\n",
    "router_prompt = PromptTemplate(\n",
    "    template=router_template,\n",
    "    input_variables=[\"input\"],\n",
    "    output_parser=RouterOutputParser(),\n",
    ")\n",
    "\n",
    "router_chain = LLMRouterChain.from_llm(llm, router_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "064dcd64-59ee-4c55-b3ad-1afa2a126dc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = MultiPromptChain(router_chain=router_chain, \n",
    "                         destination_chains=destination_chains, \n",
    "                         default_chain=default_chain, verbose=True\n",
    "                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "2e78580e-8944-4855-840d-e397d02866c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new MultiPromptChain chain...\u001b[0m\n",
      "physics: {'input': 'What is black body radiation?'}\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Black body radiation refers to the electromagnetic radiation emitted by an object that absorbs all the radiation incident upon it. A black body is a theoretical object that completely absorbs all radiation that falls on it, reflecting nothing. The spectrum of radiation emitted by a black body depends only on its temperature, and not on its composition or any other feature. As the temperature of the black body increases, the radiation becomes brighter and its peak wavelength shifts towards the shorter (blue) end of the spectrum. This phenomenon is known as Wien’s displacement law. Black body radiation has been used to explain various phenomena in physics, including the observed spectrum of stars and the cosmic microwave background radiation.'"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.run(\"What is black body radiation?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "d56b0656-a042-4bed-83b7-bca35a137b5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new MultiPromptChain chain...\u001b[0m\n",
      "math: {'input': 'what is 2 + 2'}\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'As an AI language model, I am programmed to provide accurate and helpful responses. The answer to your question is 4.'"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.run(\"what is 2 + 2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "a4347aa6-b42f-4945-8793-31032458e744",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new MultiPromptChain chain...\u001b[0m\n",
      "History: {'input': 'When did Barack Obama serve in the office?'}\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Barack Obama served as the 44th President of the United States from January 20, 2009 to January 20, 2017.'"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.run(\"When did Barack Obama serve in the office?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "654020ce-0c37-402f-aabc-7d9d67e1c9e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#chain.run(\"Why does every cell in our body contain DNA?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "347bd488-9428-40e1-b733-e8c4d7fcd95d",
   "metadata": {},
   "source": [
    "## Question and Answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "92135fcf-e219-4b6e-bbb8-92751a61993b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import RetrievalQA\n",
    "from langchain.chat_models import AzureChatOpenAI\n",
    "from langchain.document_loaders import CSVLoader\n",
    "from langchain.vectorstores import DocArrayInMemorySearch\n",
    "from IPython.display import display, Markdown"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6f4dff7-4ba3-4c4d-9b38-ae1e2ac34ec6",
   "metadata": {},
   "source": [
    "![Simple Seuqntial Chain](../images/llm_on_docs.png)\n",
    "![Simple Seuqntial Chain](../images/embeddings.png)\n",
    "![Simple Seuqntial Chain](../images/vector_database.png)\n",
    "![Simple Seuqntial Chain](../images/vector_database2.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "a2e70575-695d-405d-a2cb-258f5777d948",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = '../data/OutdoorClothingCatalog_1000.csv'\n",
    "loader = CSVLoader(file_path=file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "5479a22a-d3f2-4c7b-9fe2-4235516f0f69",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.indexes import VectorstoreIndexCreator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "c348a941-bd40-4b55-a22b-40b4fcc814a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = OpenAIEmbeddings(model='text-embedding-ada-002',\n",
    "                              deployment='embeddings',\n",
    "                              openai_api_base=config['OPENAI_API_BASE'],\n",
    "                              openai_api_type=config['OPENAI_API_TYPE'],\n",
    "                              openai_api_key=config['OPENAI_API_KEY'],\n",
    "                              chunk_size=1)\n",
    "index = VectorstoreIndexCreator(embedding=embeddings).from_loaders([loader])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "7eedf911-7e9c-46ca-9007-63b67798db00",
   "metadata": {},
   "outputs": [],
   "source": [
    "query =\"Please list all your shirts with sun protection in a table in markdown and summarize each one.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "477e845e-5592-4903-8efc-3be0b8d7c6de",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = index.query(query, llm=llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "9500b550-f226-4f3d-a987-2ea367e3f1cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "| Name | Description |\n",
       "| --- | --- |\n",
       "| Men's Tropical Plaid Short-Sleeve Shirt | This shirt is the lightest hot-weather shirt with a traditional relaxed fit. It offers UPF 50+ sun protection, is made of 100% polyester, is wrinkle-resistant, and has front and back venting. |\n",
       "| Men's Plaid Tropic Shirt, Short-Sleeve | Originally designed for fishing, this shirt also offers UPF 50+ sun protection. It's made of 52% polyester and 48% nylon, has front and back venting, is machine washable, and has two front pockets. |\n",
       "| Men's TropicVibe Shirt, Short-Sleeve | This shirt has built-in UPF 50+ sun protection and a traditional relaxed fit. It's made of 71% nylon and 29% polyester, is wrinkle-resistant, has front and back venting and two front pockets. |\n",
       "| Sun Shield Shirt | This high-performance sun shirt has UPF 50+ sun protection and is made of 78% nylon and 22% Lycra Xtra Life fiber. It is abrasion-resistant, wicks moisture, and is recommended by The Skin Cancer Foundation as an effective UV protectant. |\n",
       "\n",
       "All four shirts provide UPF 50+ sun protection, blocking 98% of the sun's harmful rays. They all have venting to keep you cool and dry, and they are all made with quick-drying and/or wrinkle-resistant fabric."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Markdown(response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "d7b6c17b-3c1b-4478-8d5f-3542962b2937",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = CSVLoader(file_path=file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "c1c17a54-b4aa-49e3-93a3-8ac6fda87113",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "d69789a7-5fb6-4c7c-b1d9-e8f79e31b77c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(page_content=\": 0\\nname: Women's Campside Oxfords\\ndescription: This ultracomfortable lace-to-toe Oxford boasts a super-soft canvas, thick cushioning, and quality construction for a broken-in feel from the first time you put them on. \\n\\nSize & Fit: Order regular shoe size. For half sizes not offered, order up to next whole size. \\n\\nSpecs: Approx. weight: 1 lb.1 oz. per pair. \\n\\nConstruction: Soft canvas material for a broken-in feel and look. Comfortable EVA innersole with Cleansport NXT® antimicrobial odor control. Vintage hunt, fish and camping motif on innersole. Moderate arch contour of innersole. EVA foam midsole for cushioning and support. Chain-tread-inspired molded rubber outsole with modified chain-tread pattern. Imported. \\n\\nQuestions? Please contact us for any inquiries.\", metadata={'source': '../data/OutdoorClothingCatalog_1000.csv', 'row': 0})"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "e919e158-45ae-4486-a351-4417410725b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "embed = embeddings.embed_query(\"Hi my name is Harrison\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "87ced45c-dcf0-4f94-ae15-b41bb7bd8499",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1536"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(embed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "fdd12ebe-23cd-4518-951e-e25a488d62f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.02186359278857708, 0.006734037306159735, -0.01820078119635582, -0.03919587284326553, -0.014047075994312763]\n"
     ]
    }
   ],
   "source": [
    "print(embed[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "6e51c0fb-b310-468a-8402-8d047c0493fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "db = DocArrayInMemorySearch.from_documents(\n",
    "    docs, \n",
    "    embeddings\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "c6276746-421f-4ab8-9118-d49a0d8f0f61",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"Please suggest a shirt with sunblocking\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "01c982e7-8510-4189-94e5-594321bfbb46",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = db.similarity_search(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "34c76cd0-d2bc-4160-a237-a07dc528cf3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "2d555f78-1f27-40c0-b3cb-825064e9e90a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(page_content=': 255\\nname: Sun Shield Shirt by\\ndescription: \"Block the sun, not the fun – our high-performance sun shirt is guaranteed to protect from harmful UV rays. \\n\\nSize & Fit: Slightly Fitted: Softly shapes the body. Falls at hip.\\n\\nFabric & Care: 78% nylon, 22% Lycra Xtra Life fiber. UPF 50+ rated – the highest rated sun protection possible. Handwash, line dry.\\n\\nAdditional Features: Wicks moisture for quick-drying comfort. Fits comfortably over your favorite swimsuit. Abrasion resistant for season after season of wear. Imported.\\n\\nSun Protection That Won\\'t Wear Off\\nOur high-performance fabric provides SPF 50+ sun protection, blocking 98% of the sun\\'s harmful rays. This fabric is recommended by The Skin Cancer Foundation as an effective UV protectant.', metadata={'source': '../data/OutdoorClothingCatalog_1000.csv', 'row': 255})"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "69c07f88-2d54-4e52-9c10-88ab160be5f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = db.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "2082137c-78dc-468d-a34d-013f7dbc9fd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = AzureChatOpenAI(deployment_name=config['OPENAI_MODEL_NAME'], \n",
    "                       model_name=\"gpt-35-turbo\", \n",
    "                       temperature=0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "ce0b98ec-3188-44ef-aeee-73129871faf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "qdocs = \"\".join([docs[i].page_content for i in range(len(docs))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "dd40ba57-c9ac-4777-ac8d-4fdc59d90cc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = llm.call_as_llm(f\"{qdocs} Question: Please list all your shirts with sun protection in a table in markdown and summarize each one.\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "46273505-c5e6-45ad-9cbc-d393cf81aa36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "| Shirt Name | Description |\n",
       "| --- | --- |\n",
       "| Sun Shield Shirt | High-performance sun shirt with UPF 50+ sun protection, moisture-wicking, and abrasion-resistant fabric. Recommended by The Skin Cancer Foundation. |\n",
       "| Men's Plaid Tropic Shirt | Ultracomfortable shirt with UPF 50+ sun protection, wrinkle-free fabric, and front/back cape venting. Made with 52% polyester and 48% nylon. |\n",
       "| Men's TropicVibe Shirt | Men's sun-protection shirt with built-in UPF 50+ and front/back cape venting. Made with 71% nylon and 29% polyester. |\n",
       "| Men's Tropical Plaid Short-Sleeve Shirt | Lightest hot-weather shirt with UPF 50+ sun protection, front/back cape venting, and two front bellows pockets. Made with 100% polyester. |\n",
       "\n",
       "All of these shirts provide UPF 50+ sun protection, blocking 98% of the sun's harmful rays. They are made with high-performance fabrics that are moisture-wicking, wrinkle-resistant, and abrasion-resistant. The Men's Plaid Tropic Shirt and Men's Tropical Plaid Short-Sleeve Shirt both have front/back cape venting for added breathability. The Sun Shield Shirt is recommended by The Skin Cancer Foundation."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Markdown(response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "f7ddae74-cbde-416d-9e99-17b36cca0d0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_stuff = RetrievalQA.from_chain_type(\n",
    "    llm=llm, \n",
    "    chain_type=\"stuff\", \n",
    "    retriever=retriever, \n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "51b41eba-f569-4cb3-a4d0-287530170a42",
   "metadata": {},
   "outputs": [],
   "source": [
    "query =  \"Please list all your shirts with sun protection in a table \\\n",
    "in markdown and summarize each one.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "879a7eea-7328-4d06-9ebf-d8d09c8b0272",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "response = qa_stuff.run(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "f782325c-0b26-457a-8afa-7f135a78f39f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "| Shirt Name | Description |\n",
       "| --- | --- |\n",
       "| Men's Tropical Plaid Short-Sleeve Shirt | Rated UPF 50+ for superior protection from the sun's UV rays. Made of 100% polyester and is wrinkle-resistant. With front and back cape venting that lets in cool breezes and two front bellows pockets. Provides the highest rated sun protection possible. |\n",
       "| Men's Plaid Tropic Shirt, Short-Sleeve | Rated to UPF 50+, helping you stay cool and dry. Made with 52% polyester and 48% nylon, this shirt is machine washable and dryable. Additional features include front and back cape venting, two front bellows pockets and an imported design. With UPF 50+ coverage, you can limit sun exposure and feel secure with the highest rated sun protection available. |\n",
       "| Men's TropicVibe Shirt, Short-Sleeve | Built-in UPF 50+ has the lightweight feel you want and the coverage you need when the air is hot and the UV rays are strong. Made with Shell: 71% Nylon, 29% Polyester. Lining: 100% Polyester knit mesh. Wrinkle resistant. Front and back cape venting lets in cool breezes. Two front bellows pockets. Imported. |\n",
       "| Sun Shield Shirt | High-performance sun shirt is guaranteed to protect from harmful UV rays. Made with 78% nylon, 22% Lycra Xtra Life fiber. Fits comfortably over your favorite swimsuit. Abrasion resistant for season after season of wear. |\n",
       "\n",
       "All of the shirts listed have sun protection with a UPF rating of 50+ and block 98% of the sun's harmful rays. The Men's Tropical Plaid Short-Sleeve Shirt is made of 100% polyester and has front and back cape venting and two front bellows pockets. The Men's Plaid Tropic Shirt, Short-Sleeve is made with 52% polyester and 48% nylon and has front and back cape venting and two front bellows pockets. The Men's TropicVibe Shirt, Short-Sleeve is made with Shell: 71% Nylon, 29% Polyester. Lining: 100% Polyester knit mesh and has front and back cape venting and two front bellows pockets. The Sun Shield Shirt is made with 78% nylon, 22% Lycra Xtra Life fiber and fits comfortably over your favorite swimsuit."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Markdown(response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "946e6503-57b7-4ca5-a1f4-4f3c331e0caa",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = index.query(query, llm=llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "fcd1bf74-0767-4972-936f-dfbcfefb961b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "| Shirt ID | Name | Description |\n",
       "| --- | --- | --- |\n",
       "| 618 | Men's Tropical Plaid Short-Sleeve Shirt | Rated UPF 50+ for superior protection from the sun's UV rays. Made of 100% polyester and is wrinkle-resistant. With front and back cape venting that lets in cool breezes and two front bellows pockets. |\n",
       "| 374 | Men's Plaid Tropic Shirt, Short-Sleeve | Rated to UPF 50+ and offers sun protection. Made with 52% polyester and 48% nylon, this shirt is machine washable and dryable. Additional features include front and back cape venting, two front bellows pockets. |\n",
       "| 535 | Men's TropicVibe Shirt, Short-Sleeve | Built-in UPF 50+ sun-protection shirt with the lightweight feel. Made with 71% Nylon, 29% Polyester. Wrinkle-resistant with front and back cape venting that lets in cool breezes and two front bellows pockets. |\n",
       "| 255 | Sun Shield Shirt | High-performance sun shirt that protects from harmful UV rays. Made with 78% nylon, 22% Lycra Xtra Life fiber. Wicks moisture for quick-drying comfort and fits comfortably over your favorite swimsuit. |\n",
       "\n",
       "All of the shirts listed have sun protection with a UPF rating of 50+ and block 98% of the sun's harmful rays. They are all designed to be lightweight and comfortable in hot weather. They also have additional features such as front and back cape venting and two front bellows pockets. The Sun Shield Shirt is specifically designed to be worn over a swimsuit and is abrasion-resistant for season after season of wear."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Markdown(response))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b2a847e-6d68-4ed8-b5cc-d19786fb1880",
   "metadata": {},
   "source": [
    "![Simple Seuqntial Chain](../images/stuff_method.png)\n",
    "![Simple Seuqntial Chain](../images/additional_methods.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3444d2f-9651-4d3c-b9a4-4832ffd4808a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e68dec7-59e2-4050-b7bb-ebfe18f092ff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9123888-7ddc-4e7f-b830-d2b741d9abbb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "zeiss_intel",
   "language": "python",
   "name": "zeiss_intel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
