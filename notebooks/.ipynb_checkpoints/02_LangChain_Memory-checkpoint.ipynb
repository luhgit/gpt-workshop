{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d3c3ed1e-a868-4e6c-a2aa-e40f20404851",
   "metadata": {},
   "source": [
    "# LangChain - Memory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca92c30a-b7ef-4d90-a1f1-6681ce8dd93e",
   "metadata": {},
   "source": [
    "Credit: Coursera"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "145e9ed2-4441-4da6-ac94-44c3b75eebd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "from langchain import LLMChain\n",
    "from langchain.chat_models import AzureChatOpenAI\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.prompts import ChatPromptTemplate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44096e4b-d090-4629-be03-e0e697e1692e",
   "metadata": {},
   "source": [
    "Why Memory:\n",
    "- LLMs are stateless\n",
    "    - Each transaction is independant\n",
    "- Chatbots appears to have memory by providing the full conversation as context\n",
    "- Types:\n",
    "    - ConversationBufferMemory\n",
    "    - ConversationBufferWindowMemory\n",
    "    - ConversationTokenBufferMemory\n",
    "    - ConversationSummaryMemory\n",
    "    - Vector data memory\n",
    "    - Entity memories\n",
    "    \n",
    "Chains:\n",
    "- SimpleSequentialChain\n",
    "- SequentialChain\n",
    "- RouterChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9bc9c2b7-fb3e-4e3a-b3b6-14cb5fbe8fd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../configs/config.json', 'r') as f:\n",
    "    config = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "254a9735-813c-487e-9c18-1b7343b079dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['OPENAI_API_TYPE']=config['OPENAI_API_TYPE']\n",
    "os.environ['OPENAI_API_VERSION']=config['OPENAI_API_VERSION']\n",
    "os.environ['OPENAI_API_BASE']=config['OPENAI_API_BASE']\n",
    "os.environ['OPENAI_API_KEY']=config['OPENAI_API_KEY']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9389f303-cd30-4f87-8778-e4d0d5d350c4",
   "metadata": {},
   "source": [
    "## Chatbot using Langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "add4e0c5-00ae-41fa-b1d0-6cd60a9e471b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the LLM model\n",
    "llm = AzureChatOpenAI(deployment_name=config['OPENAI_MODEL_NAME'], \n",
    "                       model_name=\"gpt-35-turbo\", \n",
    "                       temperature=0.0)\n",
    "\n",
    "memory = ConversationBufferMemory()\n",
    "conversation = ConversationChain(\n",
    "                        llm=llm, \n",
    "                        memory=memory,\n",
    "                        verbose=False\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8bd0c5ea-f644-4694-a53f-cf34d7718559",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Hello Amit, it's nice to meet you. My name is AI. How can I assist you today?\""
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input=\"Hi, my name is Amit\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2775dd82-a2da-47d8-bf39-99e828fb15db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The answer to 1+1 is 2.'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input=\"What is 1+1?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9a6c6855-3af0-4721-a35c-77db227df8aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Your name is Amit, as you mentioned earlier.'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input=\"What is my name?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "81a0ca88-efe2-4336-8b62-83eddb5a21a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Human: Hi, my name is Amit\n",
      "AI: Hello Amit, it's nice to meet you. My name is AI. How can I assist you today?\n",
      "Human: What is 1+1?\n",
      "AI: The answer to 1+1 is 2.\n",
      "Human: What is my name?\n",
      "AI: Your name is Amit, as you mentioned earlier.\n"
     ]
    }
   ],
   "source": [
    "print(memory.buffer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a441adbe-239d-432d-9f4f-dde1047fcf12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': \"Human: Hi, my name is Amit\\nAI: Hello Amit, it's nice to meet you. My name is AI. How can I assist you today?\\nHuman: What is 1+1?\\nAI: The answer to 1+1 is 2.\\nHuman: What is my name?\\nAI: Your name is Amit, as you mentioned earlier.\"}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9bef452b-2480-45a5-82fb-dd6e608a52f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "memory = ConversationBufferMemory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c651c031-513f-459f-bfbb-f49149fcae19",
   "metadata": {},
   "outputs": [],
   "source": [
    "memory.save_context({\"input\": \"Hi\"}, \n",
    "                    {\"output\": \"What's up\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d306c5b9-001f-4546-802d-68aad6620de1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Human: Hi\n",
      "AI: What's up\n"
     ]
    }
   ],
   "source": [
    "print(memory.buffer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "03aa68f0-0415-4e6c-894b-c204ac47ed0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': \"Human: Hi\\nAI: What's up\"}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a3ec9e8f-9107-4eea-9522-a4eec6d615a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "memory.save_context({\"input\": \"Not much, just hanging\"}, \n",
    "                    {\"output\": \"Cool\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "73fc9d08-937b-4002-a3fd-80326ac7e676",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': \"Human: Hi\\nAI: What's up\\nHuman: Not much, just hanging\\nAI: Cool\"}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d501206a-2d57-45e2-aef5-fe9e9a21a438",
   "metadata": {},
   "source": [
    "## ConversationBufferWindowMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f9cef86e-1955-466c-8bd8-c98a69fe3727",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationBufferWindowMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "3352b29a-2b7a-484c-988b-21a5ebf91e55",
   "metadata": {},
   "outputs": [],
   "source": [
    "memory = ConversationBufferWindowMemory(k=1)               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "135ea5c8-35d1-47a7-bb3e-c751f9f3ca0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "memory.save_context({\"input\": \"Hi\"},\n",
    "                    {\"output\": \"What's up\"})\n",
    "memory.save_context({\"input\": \"Not much, just hanging\"},\n",
    "                    {\"output\": \"Cool\"})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "476175d2-f558-4265-b728-362403ddeeb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': 'Human: Not much, just hanging\\nAI: Cool'}"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "031db1a7-42a3-44a3-9ee0-3ceb933e2535",
   "metadata": {},
   "outputs": [],
   "source": [
    "memory = ConversationBufferWindowMemory(k=1)\n",
    "conversation = ConversationChain(\n",
    "    llm=llm, \n",
    "    memory = memory,\n",
    "    verbose=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "03c1e8be-34bc-470c-b462-6b9d0332e8c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Hello Amit, it's nice to meet you. My name is AI. How can I assist you today?\""
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input=\"Hi, my name is Amit\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "976b323a-e7f1-4bf2-91e9-36a6b5eaa8a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The answer to 1+1 is 2.'"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input=\"What is 1+1?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "ceda9d2f-3e92-4499-bfe1-773bca0541c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I'm sorry, I don't have access to that information. Could you please tell me your name?\""
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input=\"What is my name?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1361a8f6-3982-46b4-863c-54b29e48a991",
   "metadata": {},
   "source": [
    "## ConversationTokenBufferMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "2400eabe-7ad7-4aba-8191-34b14b789fb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationTokenBufferMemory\n",
    "\n",
    "#memory = ConversationTokenBufferMemory(llm=llm, max_token_limit=30)\n",
    "\n",
    "#memory.save_context({\"input\": \"AI is what?!\"},\n",
    "#                    {\"output\": \"Amazing!\"})\n",
    "#memory.save_context({\"input\": \"Backpropagation is what?\"},\n",
    "#                    {\"output\": \"Beautiful!\"})\n",
    "#memory.save_context({\"input\": \"Chatbots are what?\"}, \n",
    "#                    {\"output\": \"Charming!\"})\n",
    "#memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f93cc3d8-057a-4aab-962e-787d06385d0d",
   "metadata": {},
   "source": [
    "## ConversationSummaryMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "2d41d114-8e87-4e34-8235-0dea9660ed8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationSummaryBufferMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "311d34cc-8a22-4006-8b98-ced7837221f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a long string\n",
    "#schedule = \"There is a meeting at 8am with your product team. \\\n",
    "#You will need your powerpoint presentation prepared. \\\n",
    "#9am-12pm have time to work on your LangChain \\\n",
    "#project which will go quickly because Langchain is such a powerful tool. \\\n",
    "#At Noon, lunch at the italian resturant with a customer who is driving \\\n",
    "#from over an hour away to meet you to understand the latest in AI. \\\n",
    "#Be sure to bring your laptop to show the latest LLM demo.\"\n",
    "\n",
    "#memory = ConversationSummaryBufferMemory(llm=llm, max_token_limit=100)\n",
    "#memory.save_context({\"input\": \"Hello\"}, {\"output\": \"What's up\"})\n",
    "#memory.save_context({\"input\": \"Not much, just hanging\"},\n",
    "#                    {\"output\": \"Cool\"})\n",
    "#memory.save_context({\"input\": \"What is on the schedule today?\"}, \n",
    "#                    {\"output\": f\"{schedule}\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "f546e37a-5e69-4efe-bb3d-2f423d421a0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#memory.load_memory_variables({})\n",
    "#conversation = ConversationChain(\n",
    "#    llm=llm, \n",
    "#    memory = memory,\n",
    "#    verbose=True\n",
    "#)\n",
    "\n",
    "#conversation.predict(input=\"What would be a good demo to show?\")\n",
    "#memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e907898-047f-4fc2-8cec-8bd0c0a20387",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3c75c18-97f6-4347-a024-6d6841fa742e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "221d2531-f6f0-4e2f-af58-e0d63e364658",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "zeiss_intel",
   "language": "python",
   "name": "zeiss_intel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
